import PIL
from PIL import Image

import matplotlib.pyplot as plt
import numpy
from numpy import asarray
import math

a = 0.15 * 10 ** -3;  # Width of the slit 0.09mm
d = 0.50* 10 ** -3;  # Distance between the slits 0.4mm
L = 1988 * 10 ** -3;  # Distance from slits to the screen is 480mm
lambd = 650 * (10 ** (-9))  # wavelength

# In[180]:


# load the image
image = Image.open('0.5_1st_4tha.png')
# convert image to numpy array
data = asarray(image)
print(type(data))
# summarize shape
print(data.shape)

# create Pillow image
image2 = Image.fromarray(data)
print(type(image2))

# summarize image details
print(image2.mode)
print(image2.size)

# print(data)
# print.pprint(data)
# image.getdata()
y = 650  # the pixel line number (intensity is measured from vertical axis at this number)
values = []
for horizontal in range(0, 1936):
    allvals = image.getpixel((horizontal, y))
    values.append(allvals[0])
    # print (allvals[0])

print("len", len(values))

x_ran = range(0, 1936)  # n
horizontal_values = []

# converting pixels to actual horizontal values
x_ran = range(0, 1936)  # n
for i in x_ran:
    horizontal_values = []
    if i < 700:
        horizontal_values.append(-(700 - i) * numpy.sqrt(5.86 * 10 ** (-6)))
    elif i == 700:
        horizontal_values.append(0.00001)  # so it's not zero
    elif i > 700:
        horizontal_values.append((i - 700) * numpy.sqrt(5.86 * 10 ** (-6)))

x_vals = numpy.array(horizontal_values) * 10 ** (-3) / L

# In[181]:


horizontal_err = []
vertical_err = []
for i in range(0, 1936):
    # horizontal_values.append(numpy.sqrt(((0.1/horizontal_values[i])**2)+((0.1/190.9)**2)))
    vertical_err.append(math.sqrt(values[i]))

# In[182]:


len(vertical_err)

# We will enter our data as a set of `numpy` arrays. We have our data values for x (independent variable) and y (dependent variable), and error in y values. These are the arrays `x_values`, `y_values` and `y_errors`, respectively.
#
# For this week's exercise, you can copy and paste the `y_values` and `y_errors` data from the output of the `pendulum_analysis.ipynb` notebook - the values below are just as an example.
#
# In future, you may find that instead you want to load data in from a **data file**; you can use the `numpy.loadtxt` function to do this - more information on doing this can be found in the `numpy` documentation (https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html).

# In[183]:


# x_values = numpy.array([-0.0012103718436910205, 0.0012103718436910205, 0.0036311155310730613, 0.006051859218455103, 0.008472602905837142, 0.010893346593219184, 0.013314090280601225, 0.015734833967983267, 0.01815557765536531, 0.02057632134274735, 0.02299706503012939, 0.025417808717511432, 0.027838552404893472, 0.03025929609227551, 0.032680039779657555, 0.0351007834670396, 0.037521527154421634, 0.03994227084180368, 0.04236301452918572, 0.04478375821656776, 0.0472045019039498, 0.04962524559133184, 0.05204598927871388, 0.05446673296609592, 0.056887476653477966, 0.05930822034086, 0.061728964028242045, 0.06414970771562409, 0.06657045140300613, 0.06899119509038817, 0.0714119387777702, 0.07383268246515225, 0.07625342615253429, 0.07867416983991633, 0.08109491352729838, 0.08351565721468042, 0.08593640090206246, 0.08835714458944449, 0.09077788827682653, 0.09319863196420858, 0.09561937565159062, 0.09804011933897266, 0.10046086302635471, 0.10288160671373674, 0.10530235040111878, 0.10772309408850082, 0.11014383777588287, 0.11256458146326491, 0.11498532515064695, 0.11740606883802898, 0.11982681252541103, 0.12224755621279307, 0.12466829990017511, 0.12708904358755715, 0.1295097872749392, 0.13193053096232124, 0.13435127464970328, 0.13677201833708533, 0.13919276202446737, 0.14161350571184939, 0.14403424939923143, 0.14645499308661347, 0.14887573677399552, 0.15129648046137756, 0.1537172241487596, 0.15613796783614164, 0.1585587115235237, 0.16097945521090573, 0.16340019889828777, 0.16582094258566982, 0.16824168627305186, 0.1706624299604339, 0.17308317364781592, 0.17550391733519796, 0.17792466102258, 0.18034540470996205, 0.1827661483973441, 0.18518689208472613, 0.18760763577210818, 0.19002837945949022, 0.19244912314687226, 0.1948698668342543, 0.19729061052163635, 0.1997113542090184, 0.20213209789640044, 0.20455284158378245, 0.2069735852711645, 0.20939432895854654, 0.21181507264592858, 0.21423581633331062, 0.21665656002069267, 0.2190773037080747, 0.22149804739545675, 0.2239187910828388, 0.22633953477022084, 0.22876027845760288, 0.23118102214498493, 0.23360176583236694, 0.23602250951974899, 0.23844325320713103, 0.24086399689451307, 0.24328474058189511, 0.24570548426927716, 0.2481262279566592, 0.2505469716440412, 0.25296771533142326, 0.2553884590188053, 0.25780920270618735, 0.2602299463935694, 0.26265069008095143, 0.2650714337683335, 0.2674921774557155, 0.26991292114309756, 0.2723336648304796, 0.27475440851786165, 0.2771751522052437, 0.27959589589262573, 0.2820166395800077, 0.28443738326738977, 0.2868581269547718, 0.28927887064215385, 0.2916996143295359, 0.29412035801691794, 0.2965411017043, 0.298961845391682, 0.30138258907906407, 0.3038033327664461, 0.30622407645382815, 0.3086448201412102, 0.31106556382859224, 0.3134863075159743, 0.3159070512033563, 0.31832779489073837, 0.3207485385781204, 0.32316928226550246, 0.3255900259528845, 0.32801076964026654, 0.3304315133276486, 0.33285225701503063, 0.33527300070241267, 0.3376937443897947, 0.34011448807717676, 0.34253523176455875, 0.3449559754519408, 0.34737671913932283, 0.3497974628267049, 0.3522182065140869, 0.35463895020146896, 0.357059693888851, 0.35948043757623305, 0.3619011812636151, 0.36432192495099713, 0.3667426686383792, 0.3691634123257612, 0.37158415601314326, 0.3740048997005253, 0.37642564338790735, 0.3788463870752894, 0.38126713076267144, 0.3836878744500535, 0.3861086181374355, 0.38852936182481757, 0.3909501055121996, 0.39337084919958165, 0.3957915928869637, 0.39821233657434574, 0.4006330802617278, 0.4030538239491098, 0.4054745676364918, 0.40789531132387385, 0.4103160550112559, 0.41273679869863794, 0.41515754238602, 0.417578286073402, 0.41999902976078407, 0.4224197734481661, 0.42484051713554816, 0.4272612608229302, 0.42968200451031224, 0.4321027481976943, 0.43452349188507633, 0.4369442355724584, 0.4393649792598404, 0.44178572294722246, 0.4442064666346045, 0.44662721032198655, 0.4490479540093686, 0.45146869769675063, 0.4538894413841327, 0.4563101850715147, 0.45873092875889676, 0.4611516724462788, 0.46357241613366085, 0.46599315982104283, 0.4684139035084249, 0.4708346471958069, 0.47325539088318896, 0.475676134570571, 0.47809687825795305, 0.4805176219453351, 0.48293836563271714, 0.4853591093200992, 0.4877798530074812, 0.49020059669486327, 0.4926213403822453, 0.49504208406962735, 0.4974628277570094, 0.49988357144439144, 0.5023043151317734, 0.5047250588191555, 0.5071458025065375, 0.5095665461939196, 0.5119872898813016, 0.5144080335686837, 0.5168287772560657, 0.5192495209434478, 0.5216702646308298, 0.5240910083182119, 0.5265117520055939, 0.528932495692976, 0.531353239380358, 0.53377398306774, 0.536194726755122, 0.5386154704425041, 0.5410362141298861, 0.5434569578172682, 0.5458777015046502, 0.5482984451920323, 0.5507191888794143, 0.5531399325667964, 0.5555606762541784, 0.5579814199415605, 0.5604021636289425, 0.5628229073163245, 0.5652436510037065, 0.5676643946910885, 0.5700851383784706, 0.5725058820658526, 0.5749266257532347, 0.5773473694406167, 0.5797681131279988, 0.5821888568153808, 0.5846096005027629, 0.5870303441901449, 0.589451087877527, 0.591871831564909, 0.5942925752522911, 0.596713318939673, 0.5991340626270552, 0.6015548063144371, 0.6039755500018192, 0.6063962936892012, 0.6088170373765833, 0.6112377810639653, 0.6136585247513474, 0.6160792684387294, 0.6185000121261115, 0.6209207558134935, 0.6233414995008755, 0.6257622431882576, 0.6281829868756396, 0.6306037305630217, 0.6330244742504036, 0.6354452179377857, 0.6378659616251677, 0.6402867053125498, 0.6427074489999318, 0.6451281926873139, 0.6475489363746959, 0.649969680062078, 0.65239042374946, 0.6548111674368421, 0.6572319111242241, 0.6596526548116062, 0.6620733984989882, 0.6644941421863703, 0.6669148858737523, 0.6693356295611343, 0.6717563732485163, 0.6741771169358984, 0.6765978606232804, 0.6790186043106625, 0.6814393479980445, 0.6838600916854265, 0.6862808353728086, 0.6887015790601906, 0.6911223227475727, 0.6935430664349547, 0.6959638101223368, 0.6983845538097188, 0.7008052974971009, 0.7032260411844828, 0.7056467848718649, 0.7080675285592469, 0.710488272246629, 0.712909015934011, 0.7153297596213931, 0.7177505033087751, 0.7201712469961572, 0.7225919906835392, 0.7250127343709213, 0.7274334780583033, 0.7298542217456854, 0.7322749654330674, 0.7346957091204495, 0.7371164528078314, 0.7395371964952135, 0.7419579401825955, 0.7443786838699776, 0.7467994275573596, 0.7492201712447416, 0.7516409149321237, 0.7540616586195057, 0.7564824023068878, 0.7589031459942698, 0.7613238896816519, 0.7637446333690339, 0.766165377056416, 0.768586120743798, 0.77100686443118, 0.773427608118562, 0.7758483518059441, 0.7782690954933261, 0.7806898391807082, 0.7831105828680902, 0.7855313265554723, 0.7879520702428543, 0.7903728139302364, 0.7927935576176184, 0.7952143013050005, 0.7976350449923825, 0.8000557886797646, 0.8024765323671466, 0.8048972760545287, 0.8073180197419106, 0.8097387634292926, 0.8121595071166747, 0.8145802508040567, 0.8170009944914388, 0.8194217381788208, 0.8218424818662029, 0.8242632255535849, 0.826683969240967, 0.829104712928349, 0.8315254566157311, 0.8339462003031131, 0.8363669439904952, 0.8387876876778771, 0.8412084313652592, 0.8436291750526412, 0.8460499187400233, 0.8484706624274053, 0.8508914061147874, 0.8533121498021694, 0.8557328934895515, 0.8581536371769335, 0.8605743808643156, 0.8629951245516976, 0.8654158682390797, 0.8678366119264617, 0.8702573556138437, 0.8726780993012258, 0.8750988429886077, 0.8775195866759898, 0.8799403303633718, 0.8823610740507539, 0.8847818177381359, 0.887202561425518, 0.8896233051129, 0.8920440488002821, 0.8944647924876641, 0.8968855361750462, 0.8993062798624282, 0.9017270235498103, 0.9041477672371923, 0.9065685109245744, 0.9089892546119563, 0.9114099982993384, 0.9138307419867204, 0.9162514856741025, 0.9186722293614845, 0.9210929730488666, 0.9235137167362486, 0.9259344604236307, 0.9283552041110127, 0.9307759477983947, 0.9331966914857768, 0.9356174351731588, 0.9380381788605409, 0.9404589225479228, 0.942879666235305, 0.9453004099226869, 0.947721153610069, 0.950141897297451, 0.9525626409848331, 0.9549833846722151, 0.9574041283595972, 0.9598248720469792, 0.9622456157343613, 0.9646663594217433, 0.9670871031091254, 0.9695078467965074, 0.9719285904838895, 0.9743493341712715, 0.9767700778586536, 0.9791908215460355, 0.9816115652334176, 0.9840323089207996, 0.9864530526081817, 0.9888737962955637, 0.9912945399829458, 0.9937152836703278, 0.9961360273577098, 0.9985567710450919, 1.000977514732474, 1.003398258419856, 1.0058190021072382, 1.0082397457946202, 1.0106604894820022, 1.0130812331693841, 1.0155019768567664, 1.0179227205441483, 1.0203434642315303, 1.0227642079189123, 1.0251849516062945, 1.0276056952936765, 1.0300264389810585, 1.0324471826684405, 1.0348679263558227, 1.0372886700432047, 1.0397094137305867, 1.0421301574179687, 1.0445509011053509, 1.0469716447927329, 1.0493923884801148, 1.0518131321674968, 1.054233875854879, 1.056654619542261, 1.059075363229643, 1.061496106917025, 1.063916850604407, 1.0663375942917892, 1.0687583379791712, 1.0711790816665532, 1.0735998253539352, 1.0760205690413174, 1.0784413127286994, 1.0808620564160814, 1.0832828001034633, 1.0857035437908455, 1.0881242874782275, 1.0905450311656095, 1.0929657748529915, 1.0953865185403737, 1.0978072622277557, 1.1002280059151377, 1.1026487496025197, 1.105069493289902, 1.1074902369772839, 1.1099109806646659, 1.1123317243520479, 1.11475246803943, 1.117173211726812, 1.119593955414194, 1.122014699101576, 1.124435442788958, 1.1268561864763402, 1.1292769301637222, 1.1316976738511042, 1.1341184175384862, 1.1365391612258684, 1.1389599049132504, 1.1413806486006324, 1.1438013922880144, 1.1462221359753966, 1.1486428796627786, 1.1510636233501605, 1.1534843670375425, 1.1559051107249247, 1.1583258544123067, 1.1607465980996887, 1.1631673417870707, 1.165588085474453, 1.168008829161835, 1.170429572849217, 1.1728503165365989, 1.175271060223981, 1.177691803911363, 1.180112547598745, 1.182533291286127, 1.184954034973509, 1.1873747786608913, 1.1897955223482732, 1.1922162660356552, 1.1946370097230372, 1.1970577534104194, 1.1994784970978014, 1.2018992407851834, 1.2043199844725654, 1.2067407281599476, 1.2091614718473296, 1.2115822155347116, 1.2140029592220936, 1.2164237029094758, 1.2188444465968578, 1.2212651902842397, 1.2236859339716217, 1.226106677659004, 1.228527421346386, 1.230948165033768, 1.23336890872115, 1.2357896524085321, 1.238210396095914, 1.240631139783296, 1.243051883470678, 1.24547262715806, 1.2478933708454423, 1.2503141145328243, 1.2527348582202062, 1.2551556019075882, 1.2575763455949704, 1.2599970892823524, 1.2624178329697344, 1.2648385766571164, 1.2672593203444986, 1.2696800640318806, 1.2721008077192626, 1.2745215514066446, 1.2769422950940268, 1.2793630387814088, 1.2817837824687908, 1.2842045261561728, 1.286625269843555, 1.289046013530937, 1.291466757218319, 1.293887500905701, 1.2963082445930831, 1.2987289882804651, 1.3011497319678471, 1.303570475655229, 1.305991219342611, 1.3084119630299933, 1.3108327067173753, 1.3132534504047573, 1.3156741940921393, 1.3180949377795215, 1.3205156814669035, 1.3229364251542854, 1.3253571688416674, 1.3277779125290496, 1.3301986562164316, 1.3326193999038136, 1.3350401435911956, 1.3374608872785778, 1.3398816309659598, 1.3423023746533418, 1.3447231183407238, 1.347143862028106, 1.349564605715488, 1.35198534940287, 1.354406093090252, 1.3568268367776342, 1.3592475804650161, 1.3616683241523981, 1.3640890678397801, 1.366509811527162, 1.3689305552145443, 1.3713512989019263, 1.3737720425893083, 1.3761927862766903, 1.3786135299640725, 1.3810342736514545, 1.3834550173388365, 1.3858757610262185, 1.3882965047136007, 1.3907172484009827, 1.3931379920883646, 1.3955587357757466, 1.3979794794631288, 1.4004002231505108, 1.4028209668378928, 1.4052417105252748, 1.407662454212657, 1.410083197900039, 1.412503941587421, 1.414924685274803, 1.4173454289621852, 1.4197661726495672, 1.4221869163369492, 1.4246076600243311, 1.4270284037117131, 1.4294491473990953, 1.4318698910864773, 1.4342906347738593, 1.4367113784612413, 1.4391321221486235, 1.4415528658360055, 1.4439736095233875, 1.4463943532107695, 1.4488150968981517, 1.4512358405855337, 1.4536565842729157, 1.4560773279602977, 1.4584980716476799, 1.4609188153350618, 1.4633395590224438, 1.4657603027098258, 1.468181046397208, 1.47060179008459, 1.473022533771972, 1.475443277459354, 1.4778640211467362, 1.4802847648341182, 1.4827055085215002, 1.4851262522088822, 1.4875469958962644, 1.4899677395836464, 1.4923884832710284, 1.4948092269584103, 1.4972299706457923, 1.4996507143331745, 1.5020714580205565, 1.5044922017079385, 1.5069129453953205, 1.5093336890827027, 1.5117544327700847, 1.5141751764574667, 1.5165959201448487, 1.5190166638322309, 1.5214374075196129, 1.5238581512069949, 1.5262788948943768, 1.528699638581759, 1.531120382269141, 1.533541125956523, 1.535961869643905, 1.5383826133312872, 1.5408033570186692, 1.5432241007060512, 1.5456448443934332, 1.5480655880808154, 1.5504863317681974, 1.5529070754555794, 1.5553278191429614, 1.5577485628303434, 1.5601693065177256, 1.5625900502051076, 1.5650107938924895, 1.5674315375798715, 1.5698522812672537, 1.5722730249546357, 1.5746937686420177, 1.5771145123293997, 1.579535256016782, 1.581955999704164, 1.5843767433915459, 1.5867974870789279, 1.58921823076631, 1.591638974453692, 1.594059718141074, 1.596480461828456, 1.5989012055158383, 1.6013219492032202, 1.6037426928906022, 1.6061634365779842, 1.6085841802653664, 1.6110049239527484, 1.6134256676401304, 1.6158464113275124, 1.6182671550148944, 1.6206878987022766, 1.6231086423896586, 1.6255293860770406, 1.6279501297644225, 1.6303708734518048, 1.6327916171391867, 1.6352123608265687, 1.6376331045139507, 1.640053848201333, 1.642474591888715, 1.644895335576097, 1.647316079263479, 1.649736822950861, 1.652157566638243, 1.654578310325625, 1.656999054013007, 1.6594197977003893, 1.6618405413877713, 1.6642612850751533, 1.6666820287625352, 1.6691027724499174, 1.6715235161372994, 1.6739442598246814, 1.6763650035120634, 1.6787857471994454, 1.6812064908868276, 1.6836272345742096, 1.6860479782615916, 1.6884687219489736, 1.6908894656363558, 1.6933102093237378, 1.6957309530111198, 1.6981516966985017, 1.700572440385884, 1.702993184073266, 1.705413927760648, 1.70783467144803, 1.7102554151354121, 1.7126761588227941, 1.715096902510176, 1.717517646197558, 1.7199383898849403, 1.7223591335723223, 1.7247798772597043, 1.7272006209470863, 1.7296213646344685, 1.7320421083218505, 1.7344628520092324, 1.7368835956966144, 1.7393043393839964, 1.7417250830713786, 1.7441458267587606, 1.7465665704461426, 1.7489873141335246, 1.7514080578209068, 1.7538288015082888, 1.7562495451956708, 1.7586702888830528, 1.761091032570435, 1.763511776257817, 1.765932519945199, 1.768353263632581, 1.7707740073199632, 1.7731947510073451, 1.7756154946947271, 1.7780362383821091, 1.7804569820694913, 1.7828777257568733, 1.7852984694442553, 1.7877192131316373, 1.7901399568190195, 1.7925607005064015, 1.7949814441937835, 1.7974021878811655, 1.7998229315685474, 1.8022436752559297, 1.8046644189433116, 1.8070851626306936, 1.8095059063180756, 1.8119266500054578, 1.8143473936928398, 1.8167681373802218, 1.8191888810676038, 1.821609624754986, 1.824030368442368, 1.82645111212975, 1.828871855817132, 1.8312925995045142, 1.8337133431918962, 1.8361340868792781, 1.8385548305666601, 1.8409755742540423, 1.8433963179414243, 1.8458170616288063, 1.8482378053161883, 1.8506585490035705, 1.8530792926909525, 1.8555000363783345, 1.8579207800657165, 1.8603415237530985, 1.8627622674404807, 1.8651830111278627, 1.8676037548152447, 1.8700244985026266, 1.8724452421900089, 1.8748659858773908, 1.8772867295647728, 1.8797074732521548, 1.882128216939537, 1.884548960626919, 1.886969704314301, 1.889390448001683, 1.8918111916890652, 1.8942319353764472, 1.8966526790638292, 1.8990734227512112, 1.9014941664385934, 1.9039149101259754, 1.9063356538133573, 1.9087563975007393, 1.9111771411881215, 1.9135978848755035, 1.9160186285628855, 1.9184393722502675, 1.9208601159376497, 1.9232808596250317, 1.9257016033124137, 1.9281223469997957, 1.9305430906871777, 1.9329638343745599, 1.9353845780619419, 1.9378053217493239, 1.9402260654367058, 1.942646809124088, 1.94506755281147, 1.947488296498852, 1.949909040186234, 1.9523297838736162, 1.9547505275609982, 1.9571712712483802, 1.9595920149357622, 1.9620127586231444, 1.9644335023105264, 1.9668542459979084, 1.9692749896852904, 1.9716957333726726, 1.9741164770600546, 1.9765372207474365, 1.9789579644348185, 1.9813787081222007, 1.9837994518095827, 1.9862201954969647, 1.9886409391843467, 1.9910616828717287, 1.993482426559111, 1.9959031702464929, 1.9983239139338749, 2.0007446576212566, 2.003165401308639, 2.0055861449960206, 2.008006888683403, 2.010427632370785, 2.012848376058167, 2.015269119745549, 2.017689863432931, 2.020110607120313, 2.022531350807695, 2.024952094495077, 2.027372838182459, 2.0297935818698414, 2.032214325557223, 2.0346350692446054, 2.0370558129319876, 2.0394765566193693, 2.0418973003067515, 2.0443180439941333, 2.0467387876815155, 2.0491595313688977, 2.0515802750562795, 2.0540010187436617, 2.0564217624310435, 2.0588425061184257, 2.061263249805808, 2.0636839934931897, 2.066104737180572, 2.068525480867954, 2.070946224555336, 2.073366968242718, 2.0757877119301, 2.078208455617482, 2.0806291993048642, 2.083049942992246, 2.085470686679628, 2.0878914303670104, 2.090312174054392, 2.0927329177417744, 2.095153661429156, 2.0975744051165384, 2.0999951488039206, 2.1024158924913023, 2.1048366361786846, 2.1072573798660668, 2.1096781235534485, 2.1120988672408307, 2.1145196109282125, 2.1169403546155947, 2.119361098302977, 2.1217818419903587, 2.124202585677741, 2.1266233293651227, 2.129044073052505, 2.131464816739887, 2.133885560427269, 2.136306304114651, 2.1387270478020333, 2.141147791489415, 2.1435685351767972, 2.145989278864179, 2.148410022551561, 2.1508307662389434, 2.153251509926325, 2.1556722536137074, 2.1580929973010896, 2.1605137409884714, 2.1629344846758536, 2.1653552283632354, 2.1677759720506176, 2.1701967157379998, 2.1726174594253815, 2.1750382031127637, 2.1774589468001455, 2.1798796904875277, 2.18230043417491, 2.1847211778622917, 2.187141921549674, 2.189562665237056, 2.191983408924438, 2.19440415261182, 2.196824896299202, 2.199245639986584, 2.2016663836739663, 2.204087127361348, 2.2065078710487303, 2.2089286147361125, 2.2113493584234942, 2.2137701021108764, 2.216190845798258, 2.2186115894856404, 2.2210323331730226, 2.2234530768604044, 2.2258738205477866, 2.228294564235169, 2.2307153079225506, 2.233136051609933, 2.2355567952973145, 2.2379775389846968, 2.240398282672079, 2.2428190263594607, 2.245239770046843, 2.2476605137342247, 2.250081257421607, 2.252502001108989, 2.254922744796371, 2.257343488483753, 2.2597642321711353, 2.262184975858517, 2.2646057195458993, 2.267026463233281, 2.2694472069206633, 2.2718679506080455, 2.2742886942954272, 2.2767094379828094, 2.2791301816701917, 2.2815509253575734, 2.2839716690449556, 2.2863924127323374, 2.2888131564197196, 2.291233900107102, 2.2936546437944836, 2.296075387481866, 2.2984961311692476, 2.3009168748566298, 2.303337618544012, 2.3057583622313937, 2.308179105918776, 2.310599849606158, 2.31302059329354, 2.315441336980922, 2.317862080668304, 2.320282824355686, 2.3227035680430683, 2.32512431173045, 2.3275450554178323, 2.3299657991052145, 2.3323865427925963, 2.3348072864799785, 2.3372280301673602, 2.3396487738547425, 2.3420695175421247, 2.3444902612295064, 2.3469110049168886, 2.349331748604271, 2.3517524922916526, 2.354173235979035, 2.3565939796664166, 2.359014723353799, 2.361435467041181, 2.363856210728563, 2.366276954415945, 2.3686976981033268, 2.371118441790709, 2.373539185478091, 2.375959929165473, 2.378380672852855, 2.3808014165402374, 2.383222160227619, 2.3856429039150013, 2.388063647602383, 2.3904843912897653, 2.3929051349771475, 2.3953258786645293, 2.3977466223519115, 2.4001673660392937, 2.4025881097266755, 2.4050088534140577, 2.4074295971014394, 2.4098503407888217, 2.412271084476204, 2.4146918281635856, 2.417112571850968, 2.4195333155383496, 2.421954059225732, 2.424374802913114, 2.426795546600496, 2.429216290287878, 2.43163703397526, 2.434057777662642, 2.436478521350024, 2.438899265037406, 2.441320008724788, 2.4437407524121704, 2.446161496099552, 2.4485822397869343, 2.4510029834743166, 2.4534237271616983, 2.4558444708490805, 2.4582652145364623, 2.4606859582238445, 2.4631067019112267, 2.4655274455986085, 2.4679481892859907, 2.470368932973373, 2.4727896766607547, 2.475210420348137, 2.4776311640355186, 2.480051907722901, 2.482472651410283, 2.484893395097665, 2.487314138785047, 2.489734882472429, 2.492155626159811, 2.494576369847193, 2.496997113534575, 2.499417857221957, 2.5018386009093394, 2.504259344596721, 2.5066800882841034, 2.509100831971485, 2.5115215756588674, 2.5139423193462496, 2.5163630630336313, 2.5187838067210135, 2.5212045504083958, 2.5236252940957775, 2.5260460377831597, 2.5284667814705415, 2.5308875251579237, 2.533308268845306, 2.5357290125326877, 2.53814975622007, 2.540570499907452, 2.542991243594834, 2.545411987282216, 2.547832730969598, 2.55025347465698, 2.5526742183443623, 2.555094962031744, 2.5575157057191262, 2.559936449406508, 2.56235719309389, 2.5647779367812724, 2.567198680468654, 2.5696194241560364, 2.5720401678434186, 2.5744609115308004, 2.5768816552181826, 2.5793023989055643, 2.5817231425929466, 2.5841438862803288, 2.5865646299677105, 2.5889853736550927, 2.591406117342475, 2.5938268610298567, 2.596247604717239, 2.5986683484046207, 2.601089092092003, 2.603509835779385, 2.605930579466767, 2.608351323154149, 2.610772066841531, 2.613192810528913, 2.6156135542162953, 2.618034297903677, 2.6204550415910592, 2.6228757852784415, 2.625296528965823, 2.6277172726532054, 2.630138016340587, 2.6325587600279694, 2.6349795037153516, 2.6374002474027334, 2.6398209910901156, 2.642241734777498, 2.6446624784648796, 2.6470832221522618, 2.6495039658396435, 2.6519247095270257, 2.654345453214408, 2.6567661969017897, 2.659186940589172, 2.661607684276554, 2.664028427963936, 2.666449171651318, 2.6688699153387, 2.671290659026082, 2.6737114027134643, 2.676132146400846, 2.6785528900882283, 2.68097363377561, 2.6833943774629923, 2.6858151211503745, 2.6882358648377562, 2.6906566085251384, 2.6930773522125206, 2.6954980958999024, 2.6979188395872846, 2.7003395832746664, 2.7027603269620486, 2.705181070649431, 2.7076018143368126, 2.710022558024195, 2.712443301711577, 2.7148640453989588, 2.717284789086341, 2.7197055327737227, 2.722126276461105, 2.724547020148487, 2.726967763835869, 2.729388507523251, 2.731809251210633, 2.734229994898015, 2.7366507385853973, 2.739071482272779, 2.7414922259601613, 2.7439129696475435, 2.7463337133349253, 2.7487544570223075, 2.7511752007096892, 2.7535959443970714, 2.7560166880844537, 2.7584374317718354, 2.7608581754592176, 2.7632789191466, 2.7656996628339816, 2.768120406521364, 2.7705411502087456, 2.772961893896128, 2.77538263758351, 2.7778033812708918, 2.780224124958274, 2.782644868645656, 2.785065612333038, 2.78748635602042, 2.789907099707802, 2.792327843395184, 2.7947485870825663, 2.797169330769948, 2.7995900744573303, 2.802010818144712, 2.8044315618320943, 2.8068523055194765, 2.8092730492068583, 2.8116937928942405, 2.8141145365816227, 2.8165352802690045, 2.8189560239563867, 2.8213767676437684, 2.8237975113311506, 2.826218255018533, 2.8286389987059146, 2.831059742393297, 2.833480486080679, 2.835901229768061, 2.838321973455443, 2.840742717142825, 2.843163460830207, 2.845584204517589, 2.848004948204971, 2.850425691892353, 2.852846435579735, 2.855267179267117, 2.8576879229544994, 2.860108666641881, 2.8625294103292633, 2.8649501540166455, 2.8673708977040273, 2.8697916413914095, 2.8722123850787913, 2.8746331287661735, 2.8770538724535557, 2.8794746161409375, 2.8818953598283197, 2.884316103515702, 2.8867368472030837, 2.889157590890466, 2.8915783345778476, 2.89399907826523, 2.896419821952612, 2.898840565639994, 2.901261309327376, 2.9036820530147582, 2.90610279670214, 2.908523540389522, 2.910944284076904, 2.913365027764286, 2.9157857714516684, 2.91820651513905, 2.9206272588264324, 2.923048002513814, 2.9254687462011963, 2.9278894898885786, 2.9303102335759603, 2.9327309772633425, 2.9351517209507247, 2.9375724646381065, 2.9399932083254887, 2.9424139520128705, 2.9448346957002527, 2.947255439387635, 2.9496761830750167, 2.952096926762399, 2.954517670449781, 2.956938414137163, 2.959359157824545, 2.961779901511927, 2.964200645199309, 2.9666213888866912, 2.969042132574073, 2.971462876261455, 2.9738836199488374, 2.976304363636219, 2.9787251073236014, 2.981145851010983, 2.9835665946983654, 2.9859873383857476, 2.9884080820731294, 2.9908288257605116, 2.9932495694478933, 2.9956703131352755, 2.9980910568226578, 3.0005118005100395, 3.0029325441974217, 3.005353287884804, 3.0077740315721857, 3.010194775259568, 3.0126155189469497, 3.015036262634332, 3.017457006321714, 3.019877750009096, 3.022298493696478, 3.0247192373838603, 3.027139981071242, 3.0295607247586243, 3.031981468446006, 3.0344022121333882, 3.0368229558207704, 3.039243699508152, 3.0416644431955344, 3.044085186882916, 3.0465059305702984, 3.0489266742576806, 3.0513474179450624, 3.0537681616324446, 3.056188905319827, 3.0586096490072086, 3.0610303926945908, 3.0634511363819725, 3.0658718800693547, 3.068292623756737, 3.0707133674441187, 3.073134111131501, 3.075554854818883, 3.077975598506265, 3.080396342193647, 3.082817085881029, 3.085237829568411, 3.0876585732557933, 3.090079316943175, 3.0925000606305573, 3.0949208043179395, 3.0973415480053212, 3.0997622916927035, 3.102183035380085, 3.1046037790674674, 3.1070245227548496, 3.1094452664422314, 3.1118660101296136, 3.1142867538169954, 3.1167074975043776, 3.11912824119176, 3.1215489848791416, 3.1239697285665238, 3.126390472253906, 3.1288112159412877, 3.13123195962867, 3.1336527033160517, 3.136073447003434, 3.138494190690816, 3.140914934378198, 3.14333567806558, 3.1457564217529623, 3.148177165440344, 3.1505979091277263, 3.153018652815108, 3.1554393965024903, 3.1578601401898725, 3.1602808838772543, 3.1627016275646365, 3.1651223712520182, 3.1675431149394004, 3.1699638586267826, 3.1723846023141644, 3.1748053460015466, 3.177226089688929, 3.1796468333763106, 3.182067577063693, 3.1844883207510746, 3.186909064438457, 3.189329808125839, 3.1917505518132208, 3.194171295500603, 3.196592039187985, 3.199012782875367, 3.201433526562749, 3.203854270250131, 3.206275013937513, 3.2086957576248953, 3.211116501312277, 3.2135372449996593, 3.2159579886870415, 3.2183787323744233, 3.2207994760618055, 3.2232202197491873, 3.2256409634365695, 3.2280617071239517, 3.2304824508113335, 3.2329031944987157, 3.2353239381860974, 3.2377446818734796, 3.240165425560862, 3.2425861692482436, 3.245006912935626, 3.247427656623008, 3.24984840031039, 3.252269143997772, 3.2546898876851538, 3.257110631372536, 3.259531375059918, 3.2619521187473, 3.264372862434682, 3.2667936061220644, 3.269214349809446, 3.2716350934968284, 3.27405583718421, 3.2764765808715923, 3.2788973245589745, 3.2813180682463563, 3.2837388119337385, 3.2861595556211203, 3.2885802993085025, 3.2910010429958847, 3.2934217866832665, 3.2958425303706487, 3.298263274058031, 3.3006840177454126, 3.303104761432795, 3.3055255051201766, 3.307946248807559, 3.310366992494941, 3.312787736182323, 3.315208479869705, 3.3176292235570872, 3.320049967244469, 3.322470710931851, 3.324891454619233, 3.327312198306615, 3.3297329419939974, 3.332153685681379, 3.3345744293687614, 3.3369951730561436, 3.3394159167435253, 3.3418366604309075, 3.3442574041182893, 3.3466781478056715, 3.3490988914930537, 3.3515196351804355, 3.3539403788678177, 3.3563611225551995, 3.3587818662425817, 3.361202609929964, 3.3636233536173457, 3.366044097304728, 3.36846484099211, 3.370885584679492, 3.373306328366874, 3.375727072054256, 3.378147815741638, 3.3805685594290202, 3.382989303116402, 3.385410046803784, 3.3878307904911664, 3.390251534178548, 3.3926722778659304, 3.395093021553312, 3.3975137652406944, 3.3999345089280766, 3.4023552526154583, 3.4047759963028406, 3.4071967399902228, 3.4096174836776045, 3.4120382273649867, 3.4144589710523685, 3.4168797147397507, 3.419300458427133, 3.4217212021145147, 3.424141945801897, 3.4265626894892787, 3.428983433176661, 3.431404176864043, 3.433824920551425, 3.436245664238807, 3.4386664079261893, 3.441087151613571, 3.4435078953009532, 3.445928638988335, 3.4483493826757172, 3.4507701263630994, 3.453190870050481, 3.4556116137378634, 3.4580323574252456, 3.4604531011126274, 3.4628738448000096, 3.4652945884873914, 3.4677153321747736, 3.4701360758621558, 3.4725568195495375, 3.4749775632369198, 3.4773983069243015, 3.4798190506116837, 3.482239794299066, 3.4846605379864477, 3.48708128167383, 3.489502025361212, 3.491922769048594, 3.494343512735976, 3.496764256423358, 3.49918500011074, 3.5016057437981223, 3.504026487485504, 3.5064472311728863, 3.5088679748602685, 3.5112887185476502, 3.5137094622350324, 3.516130205922414, 3.5185509496097964, 3.5209716932971786, 3.5233924369845604, 3.5258131806719426, 3.528233924359325, 3.5306546680467066, 3.533075411734089, 3.5354961554214706, 3.5379168991088528, 3.540337642796235, 3.5427583864836167, 3.545179130170999, 3.5475998738583807, 3.550020617545763, 3.552441361233145, 3.554862104920527, 3.557282848607909, 3.5597035922952913, 3.562124335982673, 3.5645450796700553, 3.566965823357437, 3.5693865670448193, 3.5718073107322015, 3.5742280544195832, 3.5766487981069655, 3.5790695417943477, 3.5814902854817294, 3.5839110291691116, 3.5863317728564934, 3.5887525165438756, 3.591173260231258, 3.5935940039186396, 3.596014747606022, 3.5984354912934036, 3.6008562349807858, 3.603276978668168, 3.6056977223555498, 3.608118466042932, 3.610539209730314, 3.612959953417696, 3.615380697105078, 3.61780144079246, 3.620222184479842, 3.6226429281672243, 3.625063671854606, 3.6274844155419883, 3.6299051592293705, 3.6323259029167523, 3.6347466466041345, 3.6371673902915163, 3.6395881339788985, 3.6420088776662807, 3.6444296213536624, 3.6468503650410447, 3.649271108728427, 3.6516918524158086, 3.654112596103191, 3.6565333397905726, 3.658954083477955, 3.661374827165337, 3.663795570852719, 3.666216314540101, 3.6686370582274828, 3.671057801914865, 3.673478545602247, 3.675899289289629, 3.678320032977011, 3.6807407766643934, 3.683161520351775, 3.6855822640391573, 3.688003007726539, 3.6904237514139213, 3.6928444951013035, 3.6952652387886853, 3.6976859824760675, 3.7001067261634497, 3.7025274698508315, 3.7049482135382137, 3.7073689572255955, 3.7097897009129777, 3.71221044460036, 3.7146311882877416, 3.717051931975124, 3.7194726756625056, 3.721893419349888, 3.72431416303727, 3.726734906724652, 3.729155650412034, 3.731576394099416, 3.733997137786798, 3.73641788147418, 3.738838625161562, 3.741259368848944, 3.7436801125363264, 3.746100856223708, 3.7485215999110904, 3.7509423435984726, 3.7533630872858543, 3.7557838309732365, 3.7582045746606183, 3.7606253183480005, 3.7630460620353827, 3.7654668057227645, 3.7678875494101467, 3.770308293097529, 3.7727290367849107, 3.775149780472293, 3.7775705241596746, 3.779991267847057, 3.782412011534439, 3.784832755221821, 3.787253498909203, 3.789674242596585, 3.792094986283967, 3.7945157299713492, 3.796936473658731, 3.799357217346113, 3.8017779610334954, 3.804198704720877, 3.8066194484082594, 3.809040192095641, 3.8114609357830234, 3.8138816794704056, 3.8163024231577873, 3.8187231668451695, 3.8211439105325518, 3.8235646542199335, 3.8259853979073157, 3.8284061415946975, 3.8308268852820797, 3.833247628969462, 3.8356683726568437, 3.838089116344226, 3.840509860031608, 3.84293060371899, 3.845351347406372, 3.847772091093754, 3.850192834781136, 3.8526135784685183, 3.8550343221559, 3.8574550658432822, 3.859875809530664, 3.862296553218046, 3.8647172969054284, 3.86713804059281, 3.8695587842801924, 3.8719795279675746, 3.8744002716549564, 3.8768210153423386, 3.8792417590297203, 3.8816625027171026, 3.8840832464044848, 3.8865039900918665, 3.8889247337792487, 3.891345477466631, 3.8937662211540127, 3.896186964841395, 3.8986077085287767, 3.901028452216159, 3.903449195903541, 3.905869939590923, 3.908290683278305, 3.910711426965687, 3.913132170653069, 3.9155529143404513, 3.917973658027833, 3.9203944017152152, 3.9228151454025975, 3.9252358890899792, 3.9276566327773614, 3.930077376464743, 3.9324981201521254, 3.9349188638395076, 3.9373396075268894, 3.9397603512142716, 3.942181094901654, 3.9446018385890356, 3.947022582276418, 3.9494433259637995, 3.9518640696511818, 3.954284813338564, 3.9567055570259457, 3.959126300713328, 3.96154704440071, 3.963967788088092, 3.966388531775474, 3.968809275462856, 3.971230019150238, 3.9736507628376203, 3.976071506525002, 3.9784922502123843, 3.980912993899766, 3.9833337375871483, 3.9857544812745305, 3.9881752249619122, 3.9905959686492944, 3.9930167123366767, 3.9954374560240584, 3.9978581997114406, 4.000278943398823, 4.0026996870862055, 4.005120430773587, 4.007541174460969, 4.009961918148351, 4.012382661835733, 4.014803405523115, 4.017224149210497, 4.01964489289788, 4.022065636585261, 4.024486380272643, 4.026907123960026, 4.029327867647408, 4.031748611334789, 4.034169355022172, 4.036590098709554, 4.0390108423969355, 4.041431586084317, 4.0438523297717, 4.046273073459082, 4.0486938171464635, 4.051114560833846, 4.053535304521228, 4.05595604820861, 4.058376791895992, 4.060797535583374, 4.063218279270756, 4.0656390229581385, 4.06805976664552, 4.070480510332902, 4.072901254020285, 4.0753219977076665, 4.077742741395048, 4.08016348508243, 4.082584228769813, 4.085004972457194, 4.087425716144576, 4.089846459831959, 4.092267203519341, 4.094687947206722, 4.097108690894105, 4.099529434581487, 4.1019501782688685, 4.104370921956251, 4.106791665643633, 4.109212409331015, 4.1116331530183965, 4.114053896705779, 4.116474640393161, 4.118895384080543, 4.121316127767925, 4.123736871455307, 4.126157615142689, 4.1285783588300715, 4.130999102517453, 4.133419846204835, 4.135840589892218, 4.1382613335795995, 4.140682077266981, 4.143102820954364, 4.145523564641746, 4.147944308329127, 4.150365052016509, 4.152785795703892, 4.155206539391274, 4.157627283078655, 4.160048026766038, 4.16246877045342, 4.1648895141408016, 4.167310257828184, 4.169731001515566, 4.172151745202948, 4.17457248889033, 4.176993232577712, 4.179413976265094, 4.181834719952476, 4.184255463639858, 4.18667620732724, 4.189096951014622, 4.1915176947020045, 4.193938438389386, 4.196359182076768, 4.198779925764151, 4.2012006694515325, 4.203621413138914, 4.206042156826297, 4.208462900513679, 4.21088364420106, 4.213304387888443, 4.215725131575825, 4.218145875263207, 4.220566618950588, 4.222987362637971, 4.225408106325353, 4.227828850012735, 4.230249593700117, 4.232670337387499, 4.235091081074881, 4.237511824762263, 4.239932568449645, 4.242353312137027, 4.24477405582441, 4.247194799511791, 4.249615543199173, 4.252036286886555, 4.2544570305739375, 4.256877774261319, 4.259298517948701, 4.261719261636084, 4.2641400053234655, 4.266560749010847, 4.26898149269823, 4.271402236385612, 4.273822980072993, 4.276243723760376, 4.278664467447758, 4.28108521113514, 4.283505954822521, 4.285926698509904, 4.288347442197286, 4.290768185884668, 4.29318892957205, 4.295609673259432, 4.298030416946814, 4.300451160634196, 4.302871904321578, 4.30529264800896, 4.307713391696343, 4.310134135383724, 4.312554879071106, 4.314975622758489, 4.3173963664458705, 4.319817110133252, 4.322237853820634, 4.324658597508017, 4.3270793411953985, 4.32950008488278, 4.331920828570163, 4.334341572257545, 4.3367623159449264, 4.339183059632309, 4.341603803319691, 4.344024547007073, 4.346445290694455, 4.348866034381837, 4.351286778069219, 4.353707521756601, 4.356128265443983, 4.358549009131365, 4.360969752818747, 4.363390496506129, 4.365811240193511, 4.368231983880893, 4.370652727568276, 4.373073471255657, 4.375494214943039, 4.377914958630422, 4.380335702317804, 4.382756446005185, 4.385177189692568, 4.38759793337995, 4.3900186770673315, 4.392439420754713, 4.394860164442096, 4.397280908129478, 4.3997016518168595, 4.402122395504242, 4.404543139191624, 4.406963882879006, 4.409384626566388, 4.41180537025377, 4.414226113941152, 4.4166468576285345, 4.419067601315916, 4.421488345003298, 4.42390908869068, 4.426329832378062, 4.428750576065444, 4.431171319752826, 4.433592063440209, 4.43601280712759, 4.438433550814972, 4.440854294502355, 4.443275038189737, 4.445695781877118, 4.448116525564501, 4.450537269251883, 4.4529580129392645, 4.455378756626647, 4.457799500314029, 4.460220244001411, 4.4626409876887925, 4.465061731376175, 4.467482475063557, 4.469903218750939, 4.472323962438321, 4.474744706125703, 4.477165449813085, 4.4795861935004675, 4.482006937187849, 4.484427680875231, 4.486848424562614, 4.4892691682499954, 4.491689911937377, 4.494110655624759, 4.496531399312142, 4.498952142999523, 4.501372886686905, 4.503793630374288, 4.50621437406167, 4.508635117749051, 4.511055861436434, 4.513476605123816, 4.5158973488111975, 4.51831809249858, 4.520738836185962, 4.523159579873344, 4.5255803235607255, 4.528001067248108, 4.53042181093549, 4.532842554622872, 4.535263298310254, 4.537684041997636, 4.540104785685018, 4.5425255293724005, 4.544946273059782, 4.547367016747164, 4.549787760434547, 4.5522085041219285, 4.55462924780931, 4.557049991496693, 4.559470735184075, 4.561891478871456, 4.564312222558838, 4.566732966246221, 4.569153709933603, 4.571574453620984, 4.573995197308367, 4.576415940995749, 4.5788366846831305, 4.581257428370513, 4.583678172057895, 4.586098915745277, 4.588519659432659, 4.590940403120041, 4.593361146807423, 4.595781890494805, 4.598202634182187, 4.600623377869569, 4.603044121556951, 4.6054648652443335, 4.607885608931715, 4.610306352619097, 4.61272709630648, 4.6151478399938615, 4.617568583681243, 4.619989327368626, 4.622410071056008, 4.624830814743389, 4.627251558430772, 4.629672302118154, 4.632093045805536, 4.634513789492917, 4.6369345331803, 4.639355276867682, 4.6417760205550636, 4.644196764242446, 4.646617507929828, 4.64903825161721, 4.651458995304592, 4.653879738991974, 4.656300482679356, 4.658721226366739, 4.66114197005412, 4.663562713741502, 4.665983457428884, 4.6684042011162665, 4.670824944803648, 4.67324568849103, 4.675666432178413, 4.6780871758657945, 4.680507919553176, 4.682928663240559])


x_values = numpy.array(horizontal_values)
y_values = numpy.array(values)
y_errors = numpy.array(vertical_err)

# It is useful to check that we have entered (or loaded) the data correctly - that there are the **same** number of values in each array. We can use an `assert` to do this; if the length of the arrays are different, it will cause an `AssertionError`.

# In[184]:


assert len(y_values) == len(horizontal_values)
print(len(horizontal_values), len(y_values))
print(len(y_errors))
print(len(x_values))
assert len(y_errors) == len(y_values)

# As good physicists, one of the things that we are trained to do is to **plot** our data as we go. Let's make a simple matplotlib graph to show our data and error bars:

# In[185]:


plt.figure(figsize=(5, 3))
plt.errorbar(horizontal_values,
             y_values,
             # yerr=y_errors, # use y_errors array for y error bars
             marker='o', markersize=1,  # circular markers at each datapoint
             linestyle='None')  # no connecting lines

plt.xlabel('distance from the centre point(mm)')  # axis labels and units
plt.ylabel('Intensity')
plt.show()


# You may want to think more about the **axis labels** and **units**...
#
# In this case it looks like a linear fit may be appropriate. We will define the functional form of the model that we will use to fit the data. In this first simple case it is a straight line; we will limit ourselves to a 2-parameter fit in order to be able to easily make a chi-squared contour plot later.
#

# Here `x` is a numpy array holding the set of values of the independent variable, and `param_vals` is a numpy array holding the parameter values: in this case the intercept and slope of the straight line. As both `x` and `param_vals` are numpy arrays the calculation is automatically vectorized.
#
# Similarly, we can define a simple quadratic model, again with two parameters:

# In[186]:


# def quadratic_model(x, *param_vals):


def intensity(xz, y, z):  # return param_vals[0] + param_vals[1]*x**2
    x = numpy.array(xz) * 10 ** (-3)
    theta = numpy.arcsin(x)
    # x=numpy.array(xz)
    ans = ((numpy.sin(math.pi * (a / y) * numpy.sin(theta))) / (math.pi * (a / y) * numpy.sin(theta))) ** 2 * (
        numpy.cos(math.pi * (d / y) * numpy.sin(theta))) ** 2
    anss = ans * z
    return anss


# **NOTE** that the definition of `quadratic_model` is slightly different; rather than explicitly specifying each parameter (`param_a` and `param_b` above) we instead take an arbitrary list of parameter values (`*param_vals`) which we can then access by index (see https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists).  The two approaches achieve the same thing - the 'explicit' approach is easier to follow, the 'implicit' approach is easier to modify.
#
#
#
# ---
#
# Next we specify which function we will use as our model, and define a numpy array containing our initial values for the parameters; our guess at the solution from which we will start the minimization. These will be the first set of values for `model_params` passed to the model function.
#
# Depending on the complexity of the problem the minimization algorithm may have difficulty finding the global minimum if the initial values are too far from the true solution. With a more complex problem it is often a good idea to adjust these by hand - or calculate appropriate values based on your data -  to obtain an initial starting point where the model is reasonably close to the data.

# In[187]:


model_function = intensity  # Note the absence of (), as we are not
# actually calling the function at this point.

initial_values = numpy.array([650 * (10 ** (-9)), 250])  # Initial guess for fit parameters
# initial_values=numpy.array([100*10**(-9),100])


# In[188]:


X = numpy.linspace(-3, 3, 1936)
Predicted = model_function(X, initial_values[0], initial_values[1]) * 1

for i in range(1300, 1320):
    print(Predicted[i], y_values[i])

print(X.shape)
print(Predicted.shape)
print('real data,', y_values)
print('prediction,', Predicted)
plt.errorbar(X, Predicted)
plt.errorbar(X, y_values)
plt.show()

# From our definitions of `linear_model` and `quadratic_model` functions, we see that `initial_values[0] = 0.0` is the initial guess at the intercept, and `initial_values[1] = 1.0` is the initial guess at the slope (`linear_model`) or the size of the quadratic term (`quadratic_model`).
#
# Most optimisation algorithms will assume that the parameters take values that are of order unity; you may find that in some cases you need to include scaling factors within the model function in order that both fitting parameters are not many orders of magnitude from 1. You will learn about why this is during your Computational Physics course.
#
# Now we can calculate the number of degrees-of-freedom by finding the number of elements in the data and initial values arrays.

# In[189]:


deg_freedom = x_values.size - initial_values.size  # Make sure you understand why!
print('DoF = {}'.format(deg_freedom))

# ---
#
# The next step is to produce a fit using `curve_fit()` function from the the ``scipy.optimize`` sub-module. The `scipy.optimize.curve_fit()` function uses a **chi-squared** minimisation internally, but does **NOT** return a chi-squared value, so you will need to calculate this yourself. However, what `scipy.optimize.curve_fit()` does do is provide values for parameter uncertainties, which you will have found tedious to determine in Excel.
#
# An **important** point, which you will not find in most tutorials or examples on `scipy.optimize.curve_fit()`, is that it should **ALWAYS** be called with the keyword parameter '`absolute_sigma=True`': This specifies that the stated error-bars do indeed represent 1 standard error in the datapoints, and so the resulting error-values also represent 1 standard error in the parameters. [Otherwise it is assumed that the error-bars indicate the relative size of the uncertainties only, and the resulting parameter uncertainties are not actually the correct standard error in the parameters.]
#
#
# ---
#
# In simple cases `scipy.optimize.curve_fit()` is called with the arguments:
#
#  - the model function, the specification of which is that it takes `x` as the first argument, and then the model parameters: : here `model_function=linear_model`, noting that both `linear_model` and `quadratic_model` matching the required function specification.
#  - x data: here `x_values`.
#  - y data: `y_values`.
#  - sigma, the y error: `y_errors`.
#  - `absolute_sigma=True`: error bars are indeed one standard deviation/standard error.
#  - p0, the starting values: `initial_values`.
#
#
# There are many additional options that can be passed to the ``curve_fit`` function; see the scipy documentation at https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html. These are not required for the simple case here, but may be for more complex data. You will learn more about how optimisation/minimisation algorithms work during your Computational Physics course.
#
#
# `scipy.optimize.curve_fit()` returns two arrays: a vector of the optimised (best-fitting) parameter values, which is commonly labelled `popt`; and the covariance matrix of the optimised parameters, which is commonly labelled `pcov`.

# In[190]:


from scipy.optimize import curve_fit

popt, pcov = curve_fit(model_function,
                       x_values,
                       y_values,
                       sigma=y_errors,
                       absolute_sigma=True,  # Don't forget this!
                       p0=initial_values)

# Once the fit completes successfully (i.e. without generating any error messages) we can print the vector of optimised parameter values `popt`. We will return to the covariance matrix `pcov` later.

# In[191]:


print('optimised parameters array popt = {}'.format(popt))

a_solution, b_solution = popt

# or equivalently,
# a_solution = popt[0]
# b_solution = popt[1]

print('best linear fit a = {} a_units?'.format(a_solution))
print('best linear fit b = {} b_units?'.format(b_solution))


# Remember that we need to determine chi-squared for ourselves: we define a function to calculate chi-squared, based on:
# - the arbitrarily-sized array of model parameters `model_params` for which we wish to determine the chi-squared value; these may already have been optimised to find the best fit, with  the lowest value for chi-squared
# - the model function `model` which will be passed, for example, the `linear_model` or `quadratic_model` functions defined above
# - our datapoint values and error-bars.
#
# **Note** that the call to the `model` function **'unpacks'** the array `model_params` using the * operator, so as to match the specifications of `linear_model` and `quadratic_model` above (the specification of which was required by `scipy.optimize.curve_fit()`) - see https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists.

# In[192]:


def chi_squared(model_params, model, x_data, y_data, y_error):
    return numpy.sum(((y_data - model(x_data, *model_params)) / y_error) ** 2)


# You should recognise that the returned value represents the sum of the squares of the normalised residuals. The above code is equavalent to
# ```Python
# def chi_squared(model_params, model, x_data, y_data, y_error):
#     chi_sq=0
#     for i in range(len(x_data)):
#         chi_sq += ((y_data[i] - model(x_data[i], *model_params))/y_error[i])**2
#     return chi_sq
# ```
# Again, as all variables (and the result of calling `model`) are numpy arrays of the same size, the calculation can be vectorised.
#
#
# Now we can calculate the minimized value for chi_squared using this function with the array of optimised parameters generated by `scipy.optimize.curve_fit()`:

# In[193]:


chisq_min = chi_squared(popt,  # pass the array - no need to unpack
                        model_function,
                        x_values,
                        y_values,
                        y_errors)

print('minimised chi-squared = {}'.format(chisq_min))

# In[194]:


chisq_min = chi_squared(initial_values,  # pass the array - no need to unpack
                        model_function,
                        x_values,
                        y_values,
                        y_errors)

print('minimised chi-squared = {}'.format(chisq_min))

# Note that these values are not output to a sensible number of significant figures...
#
# We can also calculate the reduced chi-squared associated with the best-fitting parameters, using the number of degrees-of-freedom determined previously.

# In[195]:


chisq_reduced = chisq_min / deg_freedom
print('reduced chi^2 = {}'.format(chisq_reduced))

# Next, we can calculate the 'P-value', as described in 'Introduction to the chi-squared statistic', and the related 'online Excel exercise'. ``scipy.stats.chi2.sf`` is the Python equivalent of the ``chidist`` function in Excel.

# In[196]:


import scipy.stats

P_value = scipy.stats.chi2.sf(chisq_min, deg_freedom)
print('P(chi^2_min, DoF) = {}'.format(P_value))

# ---
#
# To demonstrate that `scipy.optimize.curve_fit()` does indeed perform a chi-squared minimisation we can repeat such a direct minimisation ourselves: we can use the related function `scipy.optimize.minimize()` (https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) on our `chi_squared()` function - again passing it `model_function` and our data as arguments - and demonstrate that it produces the exact same result.
#
# Do **not** worry about the details of using `scipy.optimize.minimize()` - you should not use this to fit data since the execution is less robust than `scipy.optimize.curve_fit()`, and this approach will often fail to converge for complex problems; this is just an illustrative example.

# In[197]:


from scipy.optimize import minimize

fit_minimize = minimize(chi_squared,
                        initial_values,
                        args=(model_function,
                              x_values,
                              y_values,
                              y_errors))

print(fit_minimize.success)  # Did the minimisation complete successfully?
print(fit_minimize.message)  # Additional termination output information
# Resulting best fit parameter array is output as fit_minimize.x
print('best fit a = {} a_units?'.format(fit_minimize.x[0]))
print('best fit b = {} b_units?'.format(fit_minimize.x[1]))
# Minimized value for chisq function is fit_minimize.fun
print('minimised chi-squared = {}'.format(fit_minimize.fun))

Predicted = model_function(X, fit_minimize.x[0], fit_minimize.x[1]) * 1
Predicted.tolist()

# We should find that determining the minimum chi-squared produces the same optimised parameter values, and minimum chi-squared, as does optimising the parameters using `scipy.optimize.curve_fit()`.
#
# ---
#
# Assuming that the reduced chi-squared for the fit provides a value indicating that our model **is** an **acceptably good description** of our data, we should inspect a plot of the fit against the data to check that this is indeed the case.

# In[198]:


plt.figure(figsize=(5, 3))
plt.errorbar(x_values,
             y_values,
             yerr=y_errors,
             marker='o', markersize=1,
             linestyle='None')

plt.xlabel('distance from the centre point(mm)')  # Axis labels
plt.ylabel('Intensity')

# Generate best fit using model function and best fit parameters,
# and add to plot
fit_line = model_function(x_values, *popt)  # need to unpack popt here
plt.plot(x_values, fit_line, 'r')
plt.show()

# In[199]:


import seaborn as sns
import pandas

x = x_values.tolist()
X1 = numpy.linspace(-3, 3, 1936)
x1 = X1.tolist()
y = y_values.tolist()
y2 = Predicted.tolist()

df1 = pandas.DataFrame({"Distance from the centre point(mm)": x, "Data": y})
df2 = pandas.DataFrame({"Distance from the centre point(mm)": x1, "Predicted intensity": y2})

gf = sns.jointplot(data=df1, x="Distance from the centre point(mm)", y="Data", s=50, color='blue')
gf.ax_joint.errorbar(x, y, yerr=y_errors, fmt='--', color='red',
                     ecolor='lightgray', elinewidth=0.001, capsize=0)
#gf.ax_joint.xticks(numpy.arange(-2, 2, step=0.2))

# In[200]:


hues = []

for i in range(0, 968):
    ind = 1935 - i
    hues.append(x[ind])

for i in range(968, 1936):
    ind = i
    hues.append(x[i])

graph = sns.jointplot(data=df1, x="Distance from the centre point(mm)", y="Data",
                      cmap="Blues", kind="kde", marginal_kws={"color": "r", "alpha": .4}, shade=True,
                      alpha=.1)  ## CHANGE HERE

vert_err = numpy.array(y_errors)
df4 = pandas.DataFrame({"Distance from the centre point(mm)": x, "Error": vert_err})
graph.x = df2["Distance from the centre point(mm)"]
graph.y = df2["Predicted intensity"]
graph.ax_joint.scatter(data=df1, x="Distance from the centre point(mm)", alpha=.9, y="Data", c='dodgerblue', marker='o',
                       s=1)
graph.plot_joint(sns.scatterplot, color='orangered', alpha=1, label='Predicted intensity', marker='o', s=10)
graph.plot_joint(sns.scatterplot, palette="Reds_r", hue=hues, legend=None, marker='D', s=10)
## CHANGE HERE
graph.set_axis_labels()

graph.ax_joint.errorbar(x, y, yerr=y_errors, color='dodgerblue', ecolor='lightblue', fmt='o', markersize=1, linewidth=1)

graph.plot_marginals(sns.kdeplot, color='dodgerblue', shade=True, alpha=.3, legend=False)
graph.ax_joint.set_xlabel('Distance from the centre point (mm)')
graph.ax_joint.set_ylabel('Intensity (count)')
graph.ax_marg_x.set_xlim(-2, 3)

f, (ax1, ax2) = plt.subplots(2)
plt.subplots_adjust(hspace=0.9)

residuals = y_values - Predicted
residuals.tolist()
leng = len(residuals)
normalised_residuals = []

# loop to find the maximum


for i in range(leng):
    normalised_residuals.append(residuals[i] / y_errors[i])
# data-model/error


nor_rid = normalised_residuals

df3 = pandas.DataFrame({"Distance from the centre point(mm)": x, "Normalised residuals": nor_rid})

graph2 = sns.residplot(x="Distance from the centre point(mm)",
                       y="Normalised residuals", color='White', data=df3, ax=ax1)
ax2 = ax1.twinx()

graph3 = sns.scatterplot(x="Distance from the centre point(mm)", y="Normalised residuals", hue="Normalised residuals",
                         data=df3, palette="magma", s=4, ax=ax2)
graph3.set(ylabel=None)

h, l = ax1.get_legend_handles_labels()
plt.legend(h[1:], l[1:], ncol=3, loc='upper center',
           bbox_to_anchor=[3.0, 0.0],
           columnspacing=0.0, labelspacing=0.0,
           handletextpad=0.0, handlelength=0.0,
           fancybox=False, shadow=False)

sns.set_style('white', {'axes.linewidth': 0.5})

plt.show()

# In[201]:


residuals = y_values - Predicted
residuals.tolist()

# normalize
# durbin watson statistic  #contract and expand


df3 = pandas.DataFrame({"Distance from the centre point(mm)": x, "residuals": residuals})

sns.relplot(x="Distance from the centre point(mm)",
            y="residuals", hue="residuals",
            data=df3, palette="magma", s=4)

f, (ax1, ax2) = plt.subplots(2)
sns.residplot(x, y, ax=ax1)
sns.kdeplot(x, ax=ax2)

# DurbinWatson

leng = len(residuals)
normalised_residuals = []

x_max = 0
x_min = 0

# loop to find the maximum

for i in range(leng):
    if residuals[i] > x_max:
        x_max = residuals[i]

for i in range(1, leng):
    if residuals[i] < residuals[i - 1]:
        x_min = residuals[i]

print(x_max, x_min)
shifted_rid = []
# normalization
for i in range(leng):
    normalised_residuals.append((residuals[i] - x_min) / (x_max - x_min))

shifted_rid = []

for i in range(leng - 1):
    shifted_rid.append(normalised_residuals[i + 1])

shifted_rid.append(0)

print(normalised_residuals[5], shifted_rid[4], shifted_rid[6], shifted_rid[5])

import numpy as np
from statsmodels.stats.stattools import durbin_watson

g = normalised_residuals
# Using statsmodels.durbin_watson() method
gfg = durbin_watson(g)

print(gfg)

# In[202]:


from scipy.stats import pearsonr

# Pearson correlation with SciPy:


sns.set_style('white', {'axes.linewidth': 0.5})

fig, ax = plt.subplots()
ax.tick_params(bottom=True, left=True)

df4 = pandas.DataFrame({"Normalised Residual(i-1)": shifted_rid, "Normalised Residual(i)": normalised_residuals})
rp = sns.regplot(x="Normalised Residual(i-1)", y="Normalised Residual(i)", data=df4, scatter_kws={"color": "violet"},
                 line_kws={"color": "firebrick"});

corr = pearsonr(df4['Normalised Residual(i-1)'], df4['Normalised Residual(i)'])
corr = [np.round(c, 2) for c in corr]
print(corr)

text = 'r=%s, p=%s' % (corr[0], corr[1])
rp.text(0, 1, text, fontsize=12)

plt.show()

# Creating the regression plot:


# Adding the text to the Seaborn plot:

# Output: [-0.87, 0.0]


# **Note** that we could equivalently write
# ```python
# fit_line = model_function(x_values, [a_solution, b_solution])
# ```
# but this would require us to change the code if we were to add in another fitting parameter to the model function...
#
# The combination of the reduced chi-squared value, the P-value, and inspection of the fit against the data (you may like to add a residual plot yourself...) should enable you to determine whether or not the model provides an appropriate description of the data.
#
# ---
#
# In the many cases where our model function may not describe a straight line, the line of best fit likely appears jagged as values for the 'curve' are only calculated and plotted (and then joined by a straight line) at positions corresponding to the measured values of the independent variable. We can produce a smoother curve by interpolation; using our optimised parameter values and model function to calculate the line of best fit at intermediate points.

# In[203]:


smooth_xvals = numpy.linspace(min(x_values), max(x_values), 1000)
# make a smoother line - use points 1000 equally spaced
# over the range of the measured points.

plt.figure(figsize=(5, 3))
plt.errorbar(x_values,
             y_values,
             yerr=y_errors,
             marker='o', markersize=1,
             linestyle='None')

plt.xlabel('x data (units)')
plt.ylabel('y data (units)')

simulated_line = model_function(smooth_xvals, *popt)  # unpack popt!
# plt.plot(smooth_xvals, simulated_line, 'r')
# plt.show()


# In[204]:


import numpy as np
from statsmodels.stats.stattools import durbin_watson

g = residuals
# Using statsmodels.durbin_watson() method
gfg = durbin_watson(g)

print('durbin_watson', gfg)

# With a straight line fit there is no noticeable difference. However, that this approach produces a smoother line of best fit will be apparent when you use a different functional form to model your data.
#
# ---
#
# # Parameter uncertainties
#
#
# We can extract the parameter uncertainties from the 'covariance' matrix which is calculated as part of the minimization within `scipy.optimize.curve_fit()`. This approach is described in chapter 7 of 'Measurements and Their Uncertainties'. The uncertainty in the $j$th parameter, $\sigma_j$, is given by the square-root of the $j$th diagonal element of the 'covariance' matrix $C$,
#
# \\[\sigma_j = \sqrt{C_{jj}}.\\]
#
# The covariance matrix is the second result (`pcov`) that was returned by `scipy.optimize.curve_fit()` above. For a two-parameter fit, `pcov` should be a 2x2 array which we can use to calculate the parameter uncertainties:

# In[205]:


print('pcov =')
print(pcov)

errs_cov = numpy.sqrt(numpy.diag(pcov))
print('errs_cov = {}'.format(errs_cov))
a_err = errs_cov[0]
b_err = errs_cov[1]

print('Parameter a = {} +/- {}'.format(a_solution, a_err))
print('Parameter b = {} +/- {}'.format(b_solution, b_err))

# Take another moment at this point to again think about **significant figures** before reporting any of these values...
#
#
#
# ---
#
# Finally, as a demonstration, we will use a graphical approach similar to what you have done using Excel. We generate data for 2D plots of the chi-squared landscape which will allow us to produce contour plots, from which we determine the uncertainty as discussed in the previous exercises using Excel.
#
# Note that this is not a very computationally efficient approach, so unsuited to more complex problems. It will also only work 'correctly' for a 2-parameter fit... So, you are almost always better off using the approach based on the covariance matrix!
#
# The data for the 2D plot is calculated for a grid of points centered on the solution ``(a_solution, b_solution)``, with  ranges ``+/- a_range`` and ``+/- b_range``: you need to adjust these values to suit the fitted values that you obtain and the size of the error bar that you might anticipate. We will use the errors extracted from the covariance matrix to set the plotting range automatically - multiplying by 2.5 should produce a contour plot containing the first two contours, and part of the third.
#
# We generate a grid of `n_points` x `n_points` and evaluate chi-squared at each point. If you make `n_points` small the grid will be 'blocky'. If you make `n_points` large it takes longer to calculate.

# In[208]:


a_range = 2.25 * a_err
b_range = 2.25 * b_err

n_points = 100

# Generate grid and data
a_axis = numpy.linspace(a_solution - a_range, a_solution + a_range, num=n_points)
b_axis = numpy.linspace(b_solution - b_range, b_solution + b_range, num=n_points)
plot_data = numpy.zeros((n_points, n_points))

for i, b_val in enumerate(b_axis):
    for j, a_val in enumerate(a_axis):  # Nested loops for clarity...
        plot_data[i][j] = chi_squared([a_val, b_val],
                                      model_function,
                                      x_values,
                                      y_values,
                                      y_errors)

# To show that we have indeed calculated the chi-squared value at every point on the grid, first we produce a colour plot of chi-squared landscape.

# In[209]:


plt.figure(figsize=(4, 4))
im = plt.imshow(plot_data, extent=(a_axis[0], a_axis[-1],
                                   b_axis[0], b_axis[-1]),
                origin='lower', aspect='auto')

plt.xlim(a_solution - a_range, a_solution + a_range)  # axis ranges
plt.ylim(b_solution - b_range, b_solution + b_range)

plt.ylabel('Intensity (count)')  # Axis labels
plt.xlabel('Wavelength (m)')

cbar = plt.colorbar(im, orientation='vertical')  # # Colorbar and label
cbar.set_label('$\chi^2$', fontsize=12)

plt.plot(a_solution, b_solution, 'wo')  # Add in best fit point and dashed lines
plt.plot((a_solution, a_solution), (b_axis[0], b_solution),
         linestyle='--', color='w')
plt.plot((a_axis[0], a_solution), (b_solution, b_solution),
         linestyle='--', color='w')
plt.show()

# This should 'confirm' that the 'best fit' parameter values generated by `scipy.optimize.curve_fit()` do indeed correspond to the minimum in the chi-squared landscape...
#
# This information is somewhat easier to interpret when we plot it as contours instead of a colourmap... As a more useful example, we will produce a contour plot of 'delta chi-squared' (= chi-squared(a,b) - chi-squared_min).
#
# Here it is important that the calculation/plot ranges are sensible: If you have plotted the parameters over too large a range then the contours will be very small and may be hidden beneath the point marking the solution, if you have plotted the parameters over too small a range then the first contours may be beyond the range of the graph.
#
# [Some (older) versions of Python generate 'unicode' warnings on the first run through - don't worry about these!]

# In[450]:


X, Y = numpy.meshgrid(a_axis, b_axis, indexing='xy')
contour_data = plot_data - chisq_min

levels = [1, 4, 9]  # Contour levels to plot:
# delta chi-squared of 1, 4 & 9 correspond to 1, 2 & 3 standard deviations
plt.figure(figsize=(4, 4))
contour_plot = plt.contour(X, Y, contour_data,
                           levels=levels, colors='b', origin='lower')
plt.clabel(contour_plot, levels, fontsize=12, inline=1,
           fmt=r'$\chi^2 = \chi^2_{min}+%1.0f$')

plt.xlabel('a (units?)')  # Axis labels
plt.ylabel('b (units?)')

import matplotlib.ticker as ticker  # Allows you to modify the tick markers to

xtick_spacing = 0.5  # assess the errors from the chi-squared
ytick_spacing = 0.02  # contour plots.

ax = plt.gca()
ax.xaxis.set_major_locator(ticker.MultipleLocator(xtick_spacing))
ax.yaxis.set_major_locator(ticker.MultipleLocator(ytick_spacing))

plt.plot(a_solution, b_solution, 'ro')  # Add in best fit point and dashed lines to axes
plt.plot((a_solution, a_solution), (b_axis[0], b_solution), linestyle='--', color='r')
plt.plot((a_axis[0], a_solution), (b_solution, b_solution), linestyle='--', color='r')
plt.show()

# You can obtain a reasonable estimate to the uncertainty simply by reading off from the contour plot the position of the extrema of the contour where chi-squared increases by 1.
#
# However, rather than the iterative method used to extract parameter uncertainties when using Excel, it is instead possible to determine error bars from the extrema of the chi-squared+1 contour in 2D parameter space using a little `matplotlib` trickery.

# In[451]:


# Get hold of the contours from the plot
contours = contour_plot.collections[0].get_paths()
# Get the set of points constituting the one confidence-interval contour
onesigma_contour = contours[0].vertices

# Get the extrema along the two axes - max and min values
# These should be symmetric about the solution...
maxs = numpy.amax(onesigma_contour, axis=0)
mins = numpy.amin(onesigma_contour, axis=0)
errs_graphical = (maxs - mins) / 2  # Calculate one standard error in the parameters

a_error, b_error = errs_graphical

print('Parameter a = {} +/- {}'.format(a_solution, a_error))
print('Parameter b = {} +/- {}'.format(b_solution, b_error))

# Please do take another moment at this point to again think about **significant figures** before reporting any of these values...
#
#
# As an illustrative example, this should confirm that the two approaches return similar values for the uncertainty, at least within the precision that it is reasonable for us to state the uncertainty.
#
# It is worth noting that both values are approximations: The graphical approach due to the resolution of the grid of chi-squared values that we calculate (plus some internal details of how matplotlib determines the contour data); the covariance matrix determined by `scipy.optimize.curve_fit` is also an approximation which depends on the minimization method used (`scipy.optimize.curve_fit()` may choose this internally, or you may set it).
#
#
# ---
#
# ## Some important points to remember when fitting data:
#
# - In order for the optimisation to work, you may need to choose an appropriate initial condition that is close to the true minimum.
#
# - Your parameters should all be of similar order of magnitude, and ideally not far from order unity. If this does not seem to be the case, you may need to apply scaling within your model function so that your system of units has fitting parameters close to order unity (or a similar order of magnitude).
#
# - Don't accept the numerical results of the fit without thinking; check that the the results make sense - plot the data and the fit together to check that they are close.
#
# - The numerical approach to extracting parameter uncertainties will work for any number of fitting parameters, and `scipy.optimize.curve_fit()` returns the covariance matrix as part of the optimisation. But, if you want a contour plot to show in your report you will need to generate it separately.
#
#
#
# Don't forget about the 5 Golden Rules for stating values and uncertainties - a computer doesn't think about significant figures, but a physicist does!
#
#
# 1. The best estimate of the parameter is the **mean**.
# 2. The error is the **standard error** in the mean.
# 3. Round up the error to the appropriate number of **significant figures** (usually one).
# 4. Match the number of **decimal places** in the mean to the standard error.
# 5. Include the appropriate **units**.
#
#
# ---
# ---
#
# So far we have fitted a straight line to our data. Try modifying the notebook so that you fit the two-parameter quadratic model instead. You could also try to fit other functional forms with two parameters.
#
#
#
# In general you may well want to fit a model with more that two parameters. You can do this easily by making only a few modifications to the code in this notebook:
#
# You will need to define a new model function, for example
# ```Python
# def quadratic_model(x, *param_vals):
#     return param_vals[0] + param_vals[1]*x + param_vals[2]*x**2
# ```
#
# You will also need to modify the `initial_values` array to tell `scipy.optimize.curve_fit()` that your model has three parameters (or more), and will also need to add in the additional parameter(s) in places where the fitted parameter values and uncertainties output. **Note** that as a result of passing the array `popt` when calculating chi-squared, and using parameter unpacking (passing `*popt`) when plotting graphs, we don't need to make any changes to these parts of the code when changing the number of fitting parameters in the model!
#
#
#

# In[ ]:


# In[ ]:




